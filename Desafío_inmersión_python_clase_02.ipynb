{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Cfp8AtjJCSHFGaVmQINI5bWfnwbDeeVQ",
      "authorship_tag": "ABX9TyPbvEAOxBCr4z3cnEtokKj1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sebasacosta94/Inmersion-Python/blob/main/Desaf%C3%ADo_inmersi%C3%B3n_python_clase_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PROBLEMA DE NEGOCIO**\n",
        "\n",
        "La importancia de reducir el riesgo crediticio ha llevado a una institución financiera alemana a buscar soluciones innovadoras. Como científicos de datos, hemos sido convocados para construir un modelo de machine learning preciso y confiable que sea capaz de evaluar con mayor precisión la probabilidad de incumplimiento crediticio de sus clientes.\n",
        "\n",
        "Tus tareas principales serán:\n",
        "1. Preprocesamiento de Datos: Realizar limpieza de datos, manejar valores faltantes, codificación de variables categóricas y normalización/escalado de datos.\n",
        "\n",
        "2. Exploración de Datos: Analizar y comprender el conjunto de datos proporcionado, identificar variables llaves y realizar visualizaciones para entender las relaciones entre las variables y seleccionar las características relevantes.\n",
        "\n",
        "3. Construcción de Modelos: Experimentar con algunos algoritmos de machine learning como Regresión Logística, Árboles de Decisión, Random Forest, Naive Bayes, entre otros.\n",
        "\n",
        "4. Evaluación y Selección del Modelo: Evaluar los modelos utilizando métricas como precisión, recall, área bajo la curva ROC, y F1-score. Seleccionar el modelo con el mejor rendimiento para la predicción de la solvencia crediticia."
      ],
      "metadata": {
        "id": "NcgQ5mBmibre"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paso 01**\n",
        "\n",
        "**Preprocesamiento de los datos**\n",
        "\n",
        "1. Importar las Bibliotecas Necesarias para el análisis con Machine learning"
      ],
      "metadata": {
        "id": "YCeGou4jjHre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "dhwHmu3sc3Mr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Cargar y Preprocesar los Datos**\n",
        "\n",
        "Cargamos los datos para el preprocesamiento de los mismos"
      ],
      "metadata": {
        "id": "Cj3BoqA_3_qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar datos\n",
        "data = pd.read_csv('/content/drive/MyDrive/inmersion_python/german_credit.csv')\n",
        "\n",
        "# Codificar variables categóricas binarias\n",
        "label_encoder = LabelEncoder()\n",
        "binary_columns = ['telephone', 'foreign_worker']\n",
        "for col in binary_columns:\n",
        "    data[col] = label_encoder.fit_transform(data[col])\n",
        "\n",
        "# One-Hot Encoding para las demás variables categóricas\n",
        "data = pd.get_dummies(data, drop_first=True)\n",
        "\n",
        "# Normalizar datos numéricos\n",
        "scaler = StandardScaler()\n",
        "numeric_cols = data.select_dtypes(include=['int64']).columns\n",
        "data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n",
        "\n",
        "# Convertir la variable objetivo a tipo entero\n",
        "data['default'] = data['default'].astype(int)\n",
        "\n",
        "# Separar características y variable objetivo\n",
        "X = data.drop('default', axis=1)\n",
        "y = data['default']\n",
        "\n",
        "# Dividir datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
      ],
      "metadata": {
        "id": "5sQcajfT4FLp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Construir y Entrenar los Modelos**\n",
        "\n",
        "A continuación se procede a construir los modelos y a etrenarlos"
      ],
      "metadata": {
        "id": "vgvLXNSs5Nca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Regresión Logística\n",
        "log_reg = LogisticRegression(max_iter=1000)  # Aumentar el número de iteraciones\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Árbol de Decisión\n",
        "tree_clf = DecisionTreeClassifier(random_state=42)\n",
        "tree_clf.fit(X_train, y_train)\n",
        "\n",
        "# Random Forest\n",
        "rf_clf = RandomForestClassifier(random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Naive Bayes\n",
        "nb_clf = GaussianNB()\n",
        "nb_clf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "V1L4jcmO6iqE",
        "outputId": "01664396-08e0-4e5e-b0e0-bb681e42d0ad"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Evaluar los Modelos**\n",
        "\n",
        "En este paso evaluamos y comparamos los resultados de los diferentes modelos"
      ],
      "metadata": {
        "id": "EaYV5IWzB8Ug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para evaluar modelos\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        y_proba = model.predict_proba(X_test)[:, 1]\n",
        "        print('ROC AUC Score:', roc_auc_score(y_test, y_proba))\n",
        "    else:\n",
        "        y_proba = None\n",
        "\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Evaluar Regresión Logística\n",
        "print('Logistic Regression:')\n",
        "evaluate_model(log_reg, X_test, y_test)\n",
        "\n",
        "# Evaluar Árbol de Decisión\n",
        "print('Decision Tree:')\n",
        "evaluate_model(tree_clf, X_test, y_test)\n",
        "\n",
        "# Evaluar Random Forest\n",
        "print('Random Forest:')\n",
        "evaluate_model(rf_clf, X_test, y_test)\n",
        "\n",
        "# Evaluar Naive Bayes\n",
        "print('Naive Bayes:')\n",
        "evaluate_model(nb_clf, X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEdFnrtF_g3G",
        "outputId": "aa93fe36-56de-4ff4-a49a-257d9db989ad"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression:\n",
            "ROC AUC Score: 0.8080952380952382\n",
            "[[125  15]\n",
            " [ 27  33]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.89      0.86       140\n",
            "           1       0.69      0.55      0.61        60\n",
            "\n",
            "    accuracy                           0.79       200\n",
            "   macro avg       0.75      0.72      0.73       200\n",
            "weighted avg       0.78      0.79      0.78       200\n",
            "\n",
            "Decision Tree:\n",
            "ROC AUC Score: 0.6095238095238096\n",
            "[[103  37]\n",
            " [ 31  29]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.74      0.75       140\n",
            "           1       0.44      0.48      0.46        60\n",
            "\n",
            "    accuracy                           0.66       200\n",
            "   macro avg       0.60      0.61      0.61       200\n",
            "weighted avg       0.67      0.66      0.66       200\n",
            "\n",
            "Random Forest:\n",
            "ROC AUC Score: 0.7916666666666666\n",
            "[[130  10]\n",
            " [ 33  27]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.93      0.86       140\n",
            "           1       0.73      0.45      0.56        60\n",
            "\n",
            "    accuracy                           0.79       200\n",
            "   macro avg       0.76      0.69      0.71       200\n",
            "weighted avg       0.78      0.79      0.77       200\n",
            "\n",
            "Naive Bayes:\n",
            "ROC AUC Score: 0.7526190476190476\n",
            "[[102  38]\n",
            " [ 20  40]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.73      0.78       140\n",
            "           1       0.51      0.67      0.58        60\n",
            "\n",
            "    accuracy                           0.71       200\n",
            "   macro avg       0.67      0.70      0.68       200\n",
            "weighted avg       0.74      0.71      0.72       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONCLUSION**\n",
        "\n",
        "**A continuación presento los resultados de la matriz de confusión:**\n",
        "\n",
        "Verdaderos negativos: 125\n",
        "Falsos positivos: 15\n",
        "Falsos negativos: 27\n",
        "Verdaderos positivos: 33\n",
        "Métricas de clasificación:\n",
        "Precisión para la clase 0: 0.82\n",
        "Recall para la clase 0: 0.89\n",
        "F1-score para la clase 0: 0.86\n",
        "Precisión para la clase 1: 0.69\n",
        "Recall para la clase 1: 0.55\n",
        "F1-score para la clase 1: 0.61\n",
        "Precisión general (accuracy): 0.79\n",
        "\n",
        "Conclusión: La regresión logística presenta una buena precisión y un buen recall para la clase 0, pero el rendimiento es menor para la clase 1. El ROC AUC Score de 0.8081 indica un buen equilibrio entre las clases y la capacidad del modelo para distinguir entre las dos clases.\n",
        "\n",
        "**A continuación presento los resultados del árbol de decisión:**\n",
        "\n",
        "Decision Tree:\n",
        "ROC AUC Score: 0.6095\n",
        "Matriz de confusión: [[103  37]\n",
        " [ 31  29]]\n",
        "\n",
        "Verdaderos negativos: 103\n",
        "Falsos positivos: 37\n",
        "Falsos negativos: 31\n",
        "Verdaderos positivos: 29\n",
        "Métricas de clasificación:\n",
        "Precisión para la clase 0: 0.77\n",
        "Recall para la clase 0: 0.74\n",
        "F1-score para la clase 0: 0.75\n",
        "Precisión para la clase 1: 0.44\n",
        "Recall para la clase 1: 0.48\n",
        "F1-score para la clase 1: 0.46\n",
        "Precisión general (accuracy): 0.66\n",
        "Conclusión: El árbol de decisión muestra un rendimiento más bajo en comparación con otros modelos, especialmente en la clase 1, lo que se refleja en un ROC AUC Score de 0.6095. La precisión y el recall son bajos para la clase 1, indicando que el modelo tiene dificultades para identificar correctamente los casos de incumplimiento.\n",
        "\n",
        "**A continuación presento los resultados del Random forest:**\n",
        "\n",
        "ROC AUC Score: 0.7917\n",
        "Matriz de confusión: [[130  10]\n",
        " [ 33  27]]\n",
        "\n",
        "Verdaderos negativos: 130\n",
        "Falsos positivos: 10\n",
        "Falsos negativos: 33\n",
        "Verdaderos positivos: 27\n",
        "Métricas de clasificación:\n",
        "Precisión para la clase 0: 0.80\n",
        "Recall para la clase 0: 0.93\n",
        "F1-score para la clase 0: 0.86\n",
        "Precisión para la clase 1: 0.73\n",
        "Recall para la clase 1: 0.45\n",
        "F1-score para la clase 1: 0.56\n",
        "Precisión general (accuracy): 0.79\n",
        "Conclusión: El modelo Random Forest tiene un buen rendimiento en términos de precisión general y ROC AUC Score (0.7917). Sin embargo, el recall para la clase 1 es bajo, lo que indica que el modelo no es tan bueno para identificar todos los casos de incumplimiento.\n",
        "\n",
        "**A continuación presento los resultados del Naive Bayes:**\n",
        "\n",
        "Naive Bayes:\n",
        "ROC AUC Score: 0.7526\n",
        "Matriz de confusión: [[102  38]\n",
        " [ 20  40]]\n",
        "\n",
        "Verdaderos negativos: 102\n",
        "Falsos positivos: 38\n",
        "Falsos negativos: 20\n",
        "Verdaderos positivos: 40\n",
        "Métricas de clasificación:\n",
        "Precisión para la clase 0: 0.84\n",
        "Recall para la clase 0: 0.73\n",
        "F1-score para la clase 0: 0.78\n",
        "Precisión para la clase 1: 0.51\n",
        "Recall para la clase 1: 0.67\n",
        "F1-score para la clase 1: 0.58\n",
        "Precisión general (accuracy): 0.71\n",
        "Conclusión: El modelo Naive Bayes tiene un buen rendimiento en términos de ROC AUC Score (0.7526). Presenta un mejor recall para la clase 1 en comparación con otros modelos, lo que significa que identifica más casos de incumplimiento, aunque a costa de una mayor tasa de falsos positivos.\n",
        "\n",
        "**Modelo Más Eficiente**\n",
        "\n",
        "**Regresión Logística:**\n",
        "\n",
        "ROC AUC Score: 0.8081\n",
        "Buen equilibrio entre precisión y recall para ambas clases.\n",
        "\n",
        "Mejor rendimiento general con alta precisión y un buen F1-score.\n",
        "\n",
        "La Regresión Logística es el modelo más eficiente en este caso debido a su buen equilibrio entre las métricas de evaluación y un alto ROC AUC Score, lo que indica una mejor capacidad para distinguir entre las clases de incumplimiento y no incumplimiento.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1q48nDJaCogC"
      }
    }
  ]
}